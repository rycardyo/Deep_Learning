{"cells":[{"cell_type":"markdown","metadata":{"id":"A0j6qVlGCRNE"},"source":["## Criação do DataSet"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21955,"status":"ok","timestamp":1646146527429,"user":{"displayName":"EDUARDO SILVESTRE PIRES GONCALVES","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03684229115491167429"},"user_tz":180},"id":"xRJ5I6nN5Yfz","outputId":"0b2afa0e-23c9-46e1-8dcf-ba2d8b2b6596"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting albumentations==0.4.6\n","  Downloading albumentations-0.4.6.tar.gz (117 kB)\n","\u001b[K     |████████████████████████████████| 117 kB 4.9 MB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n","Collecting imgaug>=0.4.0\n","  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n","\u001b[K     |████████████████████████████████| 948 kB 9.6 MB/s \n","\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n","Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n","Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.1.post1)\n","Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n","Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n","Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n","Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.7)\n","Building wheels for collected packages: albumentations\n","  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=3c9be597e0f527a1b990340467be0b2c775d1020d2bcd44ed2e72be8f90aeca6\n","  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n","Successfully built albumentations\n","Installing collected packages: imgaug, albumentations\n","  Attempting uninstall: imgaug\n","    Found existing installation: imgaug 0.2.9\n","    Uninstalling imgaug-0.2.9:\n","      Successfully uninstalled imgaug-0.2.9\n","  Attempting uninstall: albumentations\n","    Found existing installation: albumentations 0.1.12\n","    Uninstalling albumentations-0.1.12:\n","      Successfully uninstalled albumentations-0.1.12\n","Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"]}],"source":["!pip install albumentations==0.4.6\n","import torch\n","import numpy as np\n","from skimage.transform import resize\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from torchvision.io import read_image\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2\n","import cv2\n","import glob\n","import random\n","import os\n","import pandas as pd\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","import matplotlib.pyplot as plt\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":237,"status":"ok","timestamp":1646097996135,"user":{"displayName":"EDUARDO SILVESTRE PIRES GONCALVES","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03684229115491167429"},"user_tz":180},"id":"sk_SBwwVuXwV","outputId":"d5fc41f3-aa92-4353-d2b3-4e3f3e166c97"},"outputs":[{"name":"stdout","output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"]}],"source":["# check if CUDA is available\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17822,"status":"ok","timestamp":1646098015876,"user":{"displayName":"EDUARDO SILVESTRE PIRES GONCALVES","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03684229115491167429"},"user_tz":180},"id":"CRMt1qwczGrK","outputId":"5d24d354-3ac9-4ec9-ff20-70d8ca128185"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"thtUL8wKUU48"},"outputs":[],"source":["#######################################################\n","#               Define Transforms\n","#######################################################\n","\n","train_transforms = A.Compose(\n","    [\n","        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n","        A.Resize(224,224),\n","        A.RandomBrightnessContrast(p=0.5),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.5), \n","        ToTensorV2(),\n","      \n","    ]\n",")\n","\n","test_transforms = A.Compose(\n","    [\n","        A.Resize(224,224),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n","        ToTensorV2()\n","    ]\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1646099589417,"user":{"displayName":"EDUARDO SILVESTRE PIRES GONCALVES","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03684229115491167429"},"user_tz":180},"id":"NrBGZdpyuhqo","outputId":"72928260-b962-4b6e-edaa-76bebf99cb2e"},"outputs":[{"name":"stdout","output_type":"stream","text":["train_image_path example:  /content/drive/MyDrive/Colab Notebooks/equipes_f1_train/williams/williams (25).jpg\n","class example:  williams\n","Train size: 128\n","Valid size: 32\n","Test size: 100\n"]}],"source":["####################################################\n","#       Create Train, Valid and Test sets\n","####################################################\n","\n","#Eduardo_drive (fonte)\n","# train_data_path = '/content/drive/MyDrive/Colab Notebooks/equipes_f1_train' \n","# test_data_path =  '/content/drive/MyDrive/Colab Notebooks/equipes_f1_test' \n","\n","# #Ricardo_drive (atalho)\n","# caminho_0 = '/content/drive/MyDrive/Raiz/Faculdade/2021.2/Deep Learning/{}'\n","# test_data_path = caminho_0.format('equipes_f1_test_1') \n","# train_data_path =  caminho_0.format('equipes_f1_train_1')  \n","\n","# #Ricardo_2_drive (atalho)\n","caminho_1 = '/content/drive/MyDrive/@ufg.br/Faculdade/2021.2/Deep Learning/{}'\n","test_data_path = caminho_1.format('equipes_f1_test_1') \n","train_data_path =  caminho_1.format('equipes_f1_train_1')  \n","\n","train_image_paths = [] #armazena os caminhos em uma lista\n","classes = [] #para armazenar os valores das classes\n","\n","for data_path in glob.glob(train_data_path + '/*'):\n","    classes.append(data_path.split('/')[-1]) \n","    train_image_paths.append(glob.glob(data_path + '/*'))\n","    \n","train_image_paths = [item for sublist in train_image_paths for item in sublist]\n","train_image_paths = list(train_image_paths )\n","random.shuffle(train_image_paths)\n","\n","print('train_image_path example: ', train_image_paths[0])\n","print('class example: ', classes[0])\n","\n","#2.\n","# split train valid de train paths (80,20)\n","train_image_paths, valid_image_paths = train_image_paths[:int(0.8*len(train_image_paths))], train_image_paths[int(0.8*len(train_image_paths)):] \n","\n","#3.\n","# cria test_image_paths\n","test_image_paths = []\n","for data_path in glob.glob(test_data_path + '/*'):\n","    test_image_paths.append(glob.glob(data_path + '/*'))\n","\n","test_image_paths = [item for sublist in test_image_paths for item in sublist]\n","test_image_paths = list(test_image_paths )\n","\n","print(\"Train size: {}\\nValid size: {}\\nTest size: {}\".format(len(train_image_paths), len(valid_image_paths), len(test_image_paths)))\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1646073621168,"user":{"displayName":"Ricardo Ataide","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCFi-MjTqqiPqVTnV8Rgwhi3sQblV9MxrN3TLpfR0=s64","userId":"02960667113238702017"},"user_tz":180},"id":"3akVN-BSHxPj","outputId":"ec9eb1c0-7b06-4cca-c404-83e247a26899"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/MyDrive/@ufg.br/Faculdade/2021.2/Deep Learning/equipes_f1_test_1'"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["test_data_path"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Sm6Of4fo7gFO"},"outputs":[],"source":["#######################################################\n","#      Create dictionary for class indexes\n","#######################################################\n","\n","idx_to_class = {i:j for i, j in enumerate(classes)}\n","class_to_idx = {value:key for key,value in idx_to_class.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":258,"status":"ok","timestamp":1646098201663,"user":{"displayName":"EDUARDO SILVESTRE PIRES GONCALVES","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03684229115491167429"},"user_tz":180},"id":"otQ_7SpK7mSP","outputId":"8a9b7ea8-8731-439d-dcba-bcd5682ec157"},"outputs":[{"data":{"text/plain":["{0: 'williams',\n"," 1: 'ferrari',\n"," 2: 'alpine',\n"," 3: 'alphatauri',\n"," 4: 'redbull',\n"," 5: 'astonmartin',\n"," 6: 'haas',\n"," 7: 'alpharomeo',\n"," 8: 'mercedes',\n"," 9: 'mclaren'}"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["idx_to_class"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NGiELvE79qf7"},"outputs":[],"source":["#######################################################\n","#               Define Dataset Class\n","#######################################################\n","\n","class LandmarkDataset(Dataset):\n","    def __init__(self, image_paths, transform=False):\n","        self.image_paths = image_paths\n","        self.transform = transform\n","        \n","    def __len__(self):\n","        return len(self.image_paths)\n","\n","    def __getitem__(self, idx):\n","        image_filepath = self.image_paths[idx]\n","        image = cv2.imread(image_filepath)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","        \n","        label = image_filepath.split('/')[-2]\n","        label = class_to_idx[label]\n","        if self.transform is not None:\n","            image = self.transform(image=image)[\"image\"]\n","        \n","        return image, label    \n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5L8NKUoS8Dl9"},"outputs":[],"source":["#######################################################\n","#                  Create Dataset\n","#######################################################\n","\n","train_dataset = LandmarkDataset(train_image_paths,train_transforms)\n","valid_dataset = LandmarkDataset(valid_image_paths,test_transforms) #test transforms are applied\n","test_dataset = LandmarkDataset(test_image_paths,test_transforms)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":585,"status":"ok","timestamp":1646098648061,"user":{"displayName":"EDUARDO SILVESTRE PIRES GONCALVES","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03684229115491167429"},"user_tz":180},"id":"f0fUrtON8Y0h","outputId":"f1807b3b-6d98-444f-c09c-920466b1e4cd"},"outputs":[{"name":"stdout","output_type":"stream","text":["The shape of tensor for 50th image in train dataset:  torch.Size([3, 224, 224])\n","The label for 50th image in train dataset:  0\n"]}],"source":["print('The shape of tensor for 50th image in train dataset: ',train_dataset[49][0].shape)\n","print('The label for 50th image in train dataset: ',train_dataset[49][1])"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":410,"output_embedded_package_id":"1qKXLf0ILgL3iJmyR27h2ULAZ7OqBjUF5"},"executionInfo":{"elapsed":5166,"status":"ok","timestamp":1646099631414,"user":{"displayName":"EDUARDO SILVESTRE PIRES GONCALVES","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"03684229115491167429"},"user_tz":180},"id":"wd5HtTMXHSYP","outputId":"846bca75-251d-40c0-ccf1-8cd3e80335bd"},"outputs":[{"data":{"text/plain":["Output hidden; open in https://colab.research.google.com to view."]},"metadata":{},"output_type":"display_data"}],"source":["import matplotlib.pyplot as plt\n","import copy\n","%matplotlib inline\n","\n","#######################################################\n","#                  Visualize Dataset\n","#         Images are plotted after augmentation\n","#######################################################\n","\n","def visualize_augmentations(dataset, idx=0, samples=20, cols=10, random_img = False):\n","    \n","    dataset = copy.deepcopy(dataset)\n","    #we remove the normalize and tensor conversion from our augmentation pipeline\n","    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n","    rows = samples // cols\n","    \n","        \n","    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(24, 6))\n","    for i in range(samples):\n","        if random_img:\n","            idx = np.random.randint(1,len(train_image_paths))\n","        image, lab = dataset[idx]\n","        ax.ravel()[i].imshow(image)\n","        ax.ravel()[i].set_axis_off()\n","        ax.ravel()[i].set_title(idx_to_class[lab])\n","    plt.tight_layout(pad=1)\n","    plt.show()    \n","\n","visualize_augmentations(train_dataset,np.random.randint(1,len(train_image_paths)), random_img = True)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"0Vin6i0gH4Bx"},"outputs":[],"source":["from torch.utils.data import DataLoader\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"td6-gFUlH7h4"},"outputs":[],"source":["#######################################################\n","#                  Define Dataloaders\n","#######################################################\n","batch_size = 10\n","\n","train_loader = DataLoader(\n","    train_dataset, batch_size=batch_size, shuffle=True\n",")\n","\n","valid_loader = DataLoader(\n","    valid_dataset, batch_size=batch_size, shuffle=True\n",")\n","\n","test_loader = DataLoader(\n","    test_dataset, batch_size=batch_size, shuffle=False\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1432,"status":"ok","timestamp":1646073653302,"user":{"displayName":"Ricardo Ataide","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCFi-MjTqqiPqVTnV8Rgwhi3sQblV9MxrN3TLpfR0=s64","userId":"02960667113238702017"},"user_tz":180},"id":"1yeWlFp1_q8N","outputId":"a538b9d3-1344-4baa-f6ae-13ab72ee3960"},"outputs":[{"name":"stdout","output_type":"stream","text":["VGG(\n","  (features): Sequential(\n","    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (1): ReLU(inplace=True)\n","    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (3): ReLU(inplace=True)\n","    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (6): ReLU(inplace=True)\n","    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (8): ReLU(inplace=True)\n","    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (11): ReLU(inplace=True)\n","    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (13): ReLU(inplace=True)\n","    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (15): ReLU(inplace=True)\n","    (16): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (17): ReLU(inplace=True)\n","    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (19): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (20): ReLU(inplace=True)\n","    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (22): ReLU(inplace=True)\n","    (23): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (24): ReLU(inplace=True)\n","    (25): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (26): ReLU(inplace=True)\n","    (27): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (29): ReLU(inplace=True)\n","    (30): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (31): ReLU(inplace=True)\n","    (32): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (33): ReLU(inplace=True)\n","    (34): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","    (35): ReLU(inplace=True)\n","    (36): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  )\n","  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n","  (classifier): Sequential(\n","    (0): Linear(in_features=25088, out_features=4096, bias=True)\n","    (1): ReLU(inplace=True)\n","    (2): Dropout(p=0.5, inplace=False)\n","    (3): Linear(in_features=4096, out_features=4096, bias=True)\n","    (4): ReLU(inplace=True)\n","    (5): Dropout(p=0.5, inplace=False)\n","    (6): Linear(in_features=4096, out_features=1000, bias=True)\n","  )\n",")\n"]}],"source":["import torchvision\n","from torchvision import datasets, models, transforms\n","\n","\n","#importando modelo vgg 19\n","#vgg19 = models.vgg19(pretrained=True)\n","vgg19_f = models.vgg19(pretrained=False)\n","# print(vgg19_f)\n","vgg19 = vgg19_f\n","print(vgg19)\n","# resnet = models.resnet34(pretrained=True)\n","# print(resnet)"]},{"cell_type":"markdown","metadata":{"id":"E2nCk56mCNJM"},"source":["## Modelo e treinamento"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uausE4JVCO3w"},"outputs":[],"source":["# import torch.nn as nn\n","# import torch.nn.functional as F\n","\n","# #########################################\n","# ##################  MODELO 4  ###########\n","# #########################################\n","\n","# initial_input = 224\n","# h = 512*7*7\n","# header_2 = int((h)/4)\n","# header_3 = int((h)/8)\n","# header_4 = int((h)/16)\n","# header_5 = int((h)/32)\n","\n","# out_channel_1 = 64\n","# out_channel_2 = 128\n","# out_channel_3 = 512\n","# out_channel_4 = 3584\n","\n","# class Net_4(nn.Module):\n","#   #baseado na arquitetura do vgg19\n","#     def __init__(self):\n","#         super(Net_4, self).__init__()\n","#         # convolutional layer\n","\n","#         self.conv1 = nn.Conv2d(3, out_channel_1, 2, padding=1) # 64x224x224 -> Size_output\n","#         self.conv2 = nn.Conv2d(out_channel_1,out_channel_1,3 ,padding=1) # 64x224x224 -> Size_output\n","        \n","#         #pool_/2 ->32x112x112\n","#         self.conv3 = nn.Conv2d(out_channel_1,out_channel_2,2, padding=1) #128x112x112 -> Size_output\n","#         self.conv4 = nn.Conv2d(out_channel_2,out_channel_2,2,padding=1) #128x112x112-> Size_output\n","\n","#         #pool_/4 -> 256x28x28\n","#         self.conv5 = nn.Conv2d(out_channel_2,out_channel_3,2,padding=1) #512x28x28\n","#         self.conv6 = nn.Conv2d(out_channel_3,out_channel_3,2,padding=1) #512x28x28\n","#         self.conv7 = nn.Conv2d(out_channel_3,out_channel_3,2,padding=1) #512x28x28\n","#         self.conv8 = nn.Conv2d(out_channel_3,out_channel_3,2,padding=1) #512x28x28\n","#         self.conv9 = nn.Conv2d(out_channel_3,out_channel_3,2)  #512x7x7\n","\n","#         # max pooling layer\n","#         '''\n","#         As dimensionalidades do maxpool foram pensadas buscando atender há:\n","#           1.Diminuir a dimensionalidade da rede sem perder sua complexidade\n","#          '''\n","#         self.pool_1 = nn.MaxPool2d(2, 2) \n","#         self.pool_2 = nn.MaxPool2d(4,4)\n","#         self.pool_3 = nn.MaxPool2d(7,7)\n","\n","#         #Fully-conected-layer\n","#         self.c1 = nn.Linear(h,header_2)\n","#         # self.c2 = nn.Linear(header_2,header_3)\n","#         # self.c3 = nn.Linear(header_3,header_4)\n","#         # self.c4 = nn.Linear(header_4,header_5)\n","#         self.c5 = nn.Linear(header_2,10)\n","\n","\n","#         self.dropout = nn.Dropout(0.2)\n","#     def forward(self, x):\n","#         # add sequence of convolutional and max pooling layers\n","#         x = F.relu(self.conv1(x))\n","#         x = F.relu(self.conv2(x))\n","        \n","#         #pool_/2\n","#         x = self.pool_1(x)\n","#         x = F.relu(self.conv3(x))\n","#         x = F.relu(self.conv4(x))\n","#         x = F.relu(self.conv5(x))\n","#         x = F.relu(self.conv6(x))\n","\n","#         #pool_/4\n","#         x = self.pool_2(x)\n","#         x = F.relu(self.conv7(x))\n","#         x = F.relu(self.conv8(x))\n","#         x = F.relu(self.conv9(x))\n","#         x = self.pool_2(x)\n","    \n","        \n","#         x = x.view(-1,int(h)) #reshape input\n","        \n","#         x = self.dropout(F.relu(self.c1(x)))\n","#         x = self.dropout((self.c5(x)))\n","\n","#         return x\n","# model = Net_4()\n","# print(model)\n","# if train_on_gpu:\n","#     model.cuda()\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29,"status":"ok","timestamp":1646073653303,"user":{"displayName":"Ricardo Ataide","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCFi-MjTqqiPqVTnV8Rgwhi3sQblV9MxrN3TLpfR0=s64","userId":"02960667113238702017"},"user_tz":180},"id":"ovmps0kLkyBQ","outputId":"17b8f4fd-b803-457e-85a4-fdb043b20b86"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cnn_Net(\n","  (conv0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv5): Conv2d(128, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv6): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv7): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (conv8): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n","  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n","  (pool2): MaxPool2d(kernel_size=4, stride=4, padding=0, dilation=1, ceil_mode=False)\n","  (batch_norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (batch_norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (batch_norm3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n","  (c1): Linear(in_features=25088, out_features=10, bias=True)\n","  (dropout): Dropout(p=0.25, inplace=False)\n",")\n"]}],"source":["\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","initial_input = 224\n","h = 512*7*7\n","header_2 = int((h)/4)\n","header_3 = int((h)/8)\n","header_4 = int((h)/16)\n","header_5 = int((h)/32)\n","\n","out_channel_1 = 64\n","out_channel_2 = 128\n","out_channel_3 = 512\n","\n","class Cnn_Net(nn.Module):\n","    def __init__(self):\n","        super(Cnn_Net,self).__init__()\n","            \n","        #Convolutional Layer\n","        self.conv0 = nn.Conv2d(3,out_channel_1,3,padding=1) # -> 224x224x64\n","        self.conv1 = nn.Conv2d(out_channel_1,out_channel_1,3,padding=1) # -> 224x224x64\n","        self.conv2 = nn.Conv2d(out_channel_1,out_channel_1,3,padding=1) # -> 224x224x64\n","        \n","        #Poll/2 -> 112x112x64\n","        self.conv3 = nn.Conv2d(out_channel_1,out_channel_2,3,padding=1) # ->112x112x128\n","        self.conv4 = nn.Conv2d(out_channel_2,out_channel_2,3,padding=1) # -> 112x112x128\n","       \n","        #Pool/4 -> 28x28x128\n","        self.conv5 = nn.Conv2d(out_channel_2,out_channel_3,3,padding=1) # -> 112x112x128\n","        self.conv6 = nn.Conv2d(out_channel_3,out_channel_3,3,padding=1) # -> 28x28x512\n","        self.conv7 = nn.Conv2d(out_channel_3,out_channel_3,3,padding=1) # -> 28x28x512\n","        self.conv8 = nn.Conv2d(out_channel_3,out_channel_3,3,padding=1) # -> 28x28x512\n","        #Pool/4 -> 7x7x512\n","\n","        #Max_Pool\n","        self.pool1 = nn.MaxPool2d(2,2)\n","        self.pool2 = nn.MaxPool2d(4,4)\n","\n","        #Batch_normalize\n","        self.batch_norm1 = nn.BatchNorm2d(out_channel_1)\n","        self.batch_norm2 = nn.BatchNorm2d(out_channel_2) \n","        self.batch_norm3 = nn.BatchNorm2d(out_channel_3)\n","\n","        #Fully_conected_layer\n","        self.c1 = nn.Linear(h,10)\n","        \n","        \n","        self.dropout = nn.Dropout(0.25)\n","\n","            \n","    def forward(self,x):\n","        #Agora são implementadas as \"shortcut connections\", utilizadas para\n","        #tratar o gradiente de fuga\n","        x = F.relu(self.batch_norm1(self.conv0(x)))\n","        x1 = x\n","        x = F.relu(self.batch_norm1(self.conv1(x)))\n","        x = (self.batch_norm1(self.conv2(x)))\n","        x += x1\n","        x = F.relu(x)\n","        x = self.pool1(x)\n","        \n","        \n","        x = self.dropout(x)\n","        x = F.relu(self.batch_norm2(self.conv3(x)))\n","        x2 = x\n","        x = F.relu(self.batch_norm2(self.conv4(x)))\n","        x = self.batch_norm2(self.conv4(x))\n","        #x += x2\n","        x = F.relu(x)\n","        x = self.pool2(x)\n","        x = self.dropout(x)\n","        #x3 = x\n","        x = F.relu(self.batch_norm3(self.conv5(x)))\n","        x3 = x\n","        x = F.relu(self.batch_norm3(self.conv6(x)))\n","        x = self.batch_norm3(self.conv7(x))\n","        x += x3\n","        x = F.relu(x)\n","        x = self.dropout(x)\n","       \n","        x = F.relu(self.batch_norm3(self.conv7(x)))\n","        x4 = x\n","        x = F.relu(self.batch_norm3(self.conv8(x)))\n","        x = self.batch_norm3(self.conv8(x))\n","        x += x4\n","        x = F.relu(x)\n","        x=self.pool2(x)\n","        x = self.dropout(x)\n","        \n","        #Fully-connected_layer\n","        x = x.view(-1,h)\n","        x = self.c1(x)\n","       \n","        \n","        return x\n","    \n","model = Cnn_Net()\n","print(model)\n","if train_on_gpu:\n","    model.cuda()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1646073653304,"user":{"displayName":"Ricardo Ataide","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCFi-MjTqqiPqVTnV8Rgwhi3sQblV9MxrN3TLpfR0=s64","userId":"02960667113238702017"},"user_tz":180},"id":"9XDXCErvnZJ9","outputId":"cb7c2989-1c92-42a3-9315-76e619d4e815"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mon Feb 28 18:40:44 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   71C    P0    75W / 149W |    559MiB / 11441MiB |      5%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","+-----------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18,"status":"ok","timestamp":1646073653305,"user":{"displayName":"Ricardo Ataide","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCFi-MjTqqiPqVTnV8Rgwhi3sQblV9MxrN3TLpfR0=s64","userId":"02960667113238702017"},"user_tz":180},"id":"mbLxreXtK78s","outputId":"e54e5e72-8ee0-49ff-f7f6-ccf5ee942e8f"},"outputs":[{"name":"stdout","output_type":"stream","text":["1: 50176.0, 2: 12544.0, 1: 1568.0\n"]}],"source":["#Verificando quantidade de parametros no modelo\n","initial_input = 224\n","header_1 = (((initial_input/(2**4))**2) * 256)\n","header_2 = ((header_1)/4)\n","header_3 = ((header_2)/8)\n","\n","print('1: {}, 2: {}, 1: {}'.format(header_1,header_2,header_3))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EJlqH4_SMsmS"},"outputs":[],"source":["#loss_function\n","import torch\n","criterion = torch.nn.CrossEntropyLoss()\n","\n","#optimizer function\n","lr = 0.01\n","# optimizer = torch.optim.SGD(vgg19.classifier.parameters(), lr = lr)\n","optimizer = torch.optim.SGD(model.parameters(), lr = lr)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":408},"executionInfo":{"elapsed":1075402,"status":"error","timestamp":1646077161274,"user":{"displayName":"Ricardo Ataide","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjCFi-MjTqqiPqVTnV8Rgwhi3sQblV9MxrN3TLpfR0=s64","userId":"02960667113238702017"},"user_tz":180},"id":"ORzhqF4VQUwW","outputId":"582b458e-5f36-433d-a469-3aa1d4db1576"},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch: 1 \tTraining Loss: 2.367160 \tValidation Loss: 6.240395\n","Validation loss decreased (inf --> 6.240395).  Saving model ...\n","Epoch: 2 \tTraining Loss: 2.335060 \tValidation Loss: 5.688807\n","Validation loss decreased (6.240395 --> 5.688807).  Saving model ...\n","Epoch: 3 \tTraining Loss: 2.324151 \tValidation Loss: 6.400615\n","Epoch: 4 \tTraining Loss: 2.289753 \tValidation Loss: 12.900865\n","Epoch: 5 \tTraining Loss: 2.288098 \tValidation Loss: 7.568432\n","Epoch: 6 \tTraining Loss: 2.297046 \tValidation Loss: 4.146555\n","Validation loss decreased (5.688807 --> 4.146555).  Saving model ...\n","Epoch: 7 \tTraining Loss: 2.295787 \tValidation Loss: 4.545342\n"]},{"ename":"KeyboardInterrupt","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-26-f2c880c9fd02>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;31m# update training loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;31m######################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["modelo = 'nsew_model'\n","import numpy as np\n","# number of epochs to train the model\n","n_epochs = 50 # you may increase this number to train a final model\n","\n","valid_loss_min = np.Inf # track change in validation loss\n","\n","for epoch in range(1, n_epochs+1):\n","\n","    # keep track of training and validation loss\n","    train_loss = 0.0\n","    valid_loss = 0.0\n","    if epoch == 0:\n","      epoch_last_saved = 0\n","    if (epoch_last_saved == (epoch - 15)): #caso esteja na décima época, ou, há 10 épocas em que não é identificado um mínimo error:\n","        lr = lr/2\n","        optimizer = torch.optim.SGD(model.parameters(), lr = lr) #Diminui o \"passo\" do gradiente\n","        print('Atualizando o Lr para {}'.format(lr))\n","    ###################\n","    # train the model #\n","    ###################\n","    model.train()\n","    for data, target in train_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # clear the gradients of all optimized variables\n","        optimizer.zero_grad()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # backward pass: compute gradient of the loss with respect to model parameters\n","        loss.backward()\n","        # perform a single optimization step (parameter update)\n","        optimizer.step()\n","        # update training loss\n","        train_loss += loss.item()*data.size(0)\n","        \n","    ######################    \n","    # validate the model #\n","    ######################\n","    model.eval()\n","    for data, target in valid_loader:\n","        # move tensors to GPU if CUDA is available\n","        if train_on_gpu:\n","            data, target = data.cuda(), target.cuda()\n","        # forward pass: compute predicted outputs by passing inputs to the model\n","        output = model(data)\n","        # calculate the batch loss\n","        loss = criterion(output, target)\n","        # update average validation loss \n","        valid_loss += loss.item()*data.size(0)\n","    \n","    # calculate average losses\n","    train_loss = train_loss/len(train_loader.dataset)\n","    valid_loss = valid_loss/len(valid_loader.dataset)\n","        \n","    # print training/validation statistics \n","    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n","        epoch, train_loss, valid_loss))\n","    \n","    # save model if validation loss has decreased\n","    if valid_loss <= valid_loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n","        valid_loss_min,\n","        valid_loss))\n","        # torch.save(model.state_dict(), '/content/drive/MyDrive/Colab Notebooks/models/{}.pt'.format(modelo))\n","        torch.save(model.state_dict(), '/content/drive/MyDrive/@ufg.br/Faculdade/2021.2/Deep Learning//Models/{}.pt'.format(modelo))\n","        epoch_last_saved = epoch\n","        valid_loss_min = valid_loss"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BR9V641xURp9"},"outputs":[],"source":["# model.cpu()\n","\n","modelo = 'new_model'\n","model.load_state_dict(torch.load('./models/{}.pt'.format(modelo),map_location=torch.device('cpu')))\n","# torch.save(model.state_dict(), '/content/drive/MyDrive/Raiz/Faculdade/2021.2/Deep Learning/Models/{}.pt'.format(modelo))"]},{"cell_type":"markdown","metadata":{"id":"xo86toZlWj3J"},"source":["### Testando model_1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"CH3Flpw2WmL0"},"outputs":[],"source":["# track test loss\n","def test_model(model):\n","  test_loss = 0.0\n","  class_correct = list(0. for i in range(10))\n","  class_total = list(0. for i in range(10))\n","\n","  model.eval()\n","  # iterate over test data\n","  for data, target in test_loader:\n","      # move tensors to GPU if CUDA is available\n","      if train_on_gpu:\n","          data, target = data.cuda(), target.cuda()\n","      # forward pass: compute predicted outputs by passing inputs to the model\n","      output = model(data)\n","      # calculate the batch loss\n","      loss = criterion(output, target)\n","      # update test loss \n","      test_loss += loss.item()*data.size(0)\n","      # convert output probabilities to predicted class\n","      _, pred = torch.max(output, 1)    \n","      # compare predictions to true label\n","      correct_tensor = pred.eq(target.data.view_as(pred))\n","      correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())\n","      # calculate test accuracy for each object class\n","      for i in range(batch_size):\n","          label = target.data[i]\n","          class_correct[label] += correct[i].item()\n","          class_total[label] += 1\n"," \n","  # average test loss\n","  test_loss = test_loss/len(test_loader.dataset)\n","  print('Test Loss: {:.6f}\\n'.format(test_loss))\n","\n","  for i in range(10):\n","      if class_total[i] > 0:\n","          print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (\n","              classes[i], 100 * class_correct[i] / class_total[i],\n","              np.sum(class_correct[i]), np.sum(class_total[i])))\n","      else:\n","          print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))\n","\n","  print('\\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (\n","      100. * np.sum(class_correct) / np.sum(class_total),\n","      np.sum(class_correct), np.sum(class_total)))\n","\n","test_model(model)\n"]},{"cell_type":"markdown","metadata":{"id":"AsQBVuUyWj0N"},"source":[]},{"cell_type":"markdown","metadata":{"id":"geWkdU08hSGY"},"source":["## Confusion Matrix"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iXkerQ9yp1JK"},"outputs":[],"source":["model.cpu()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xb0_FZbLhR3w"},"outputs":[],"source":["def createCM(loader,model,nClasses):\n","    from sklearn.metrics import confusion_matrix\n","    accuracy = 0\n","    CM = np.zeros((nClasses,nClasses))\n","    y_pred = []\n","    y_real = []\n","    #COLOQUE O SEU CÓDIGO AQUI\n","    with torch.no_grad():\n","       for inputs, targets in loader:\n","          outputs = model(inputs)\n","          y_pred.extend((torch.max(outputs,1)[1]).numpy())\n","          y_real.extend(targets.numpy())\n","    CM = confusion_matrix(y_real,y_pred)\n","    values_correctly = 0\n","    for l in range(0,nClasses):\n","        values_correctly += CM[l][l]\n","    accuracy = ((100/CM.sum()) * values_correctly)\n","    #Para cada classe  procura os valores do tensor que sao dessa classe, posteriormente compara com o \n","\n","\n","\n","\n","    return CM, accuracy"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W0FZImIwhX8A"},"outputs":[],"source":["#NÃO ALTERE ESTA CÉLULA\n","def plot_CM(CM,accuracy):\n","    CM = 100*CM/CM.sum(axis=1)\n","    plt.figure(figsize=(10,8))\n","    plt.imshow(CM,cmap='YlOrBr')\n","    plt.ylabel('target')\n","    plt.xlabel('prediction')\n","    plt.title('Accuracy: '+\"{:4.2f}\".format(accuracy)+'%')\n","    plt.colorbar()\n","    for i in range(CM.shape[0]):\n","        for j in range(CM.shape[1]):\n","            if CM[i,j]>70:\n","                color = \"White\"\n","            else:\n","                color = \"Black\"\n","            plt.text(j, i, \"{:.3f}\".format(CM[i,j]), ha=\"center\", va=\"center\", color=color)    \n","\n","CM_train, accuracy_train = createCM(train_loader, model, 10)\n","plot_CM(CM_train, accuracy_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Vt4qZ5KwivaA"},"outputs":[],"source":["CM_train, accuracy_train = createCM(test_loader, model, 10)\n","plot_CM(CM_train, accuracy_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BPMjHOMvixho"},"outputs":[],"source":["CM_train, accuracy_train = createCM(valid_loader, model, 10)\n","plot_CM(CM_train, accuracy_train)"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"Trabalho2 CNN Criada.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
